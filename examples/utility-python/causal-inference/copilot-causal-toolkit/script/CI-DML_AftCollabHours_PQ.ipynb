{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "568a5bdb",
   "metadata": {},
   "source": [
    "# Causal inference on Burnout Risk for [YOUR COMPANY]\n",
    "\n",
    "## Research question\n",
    "\n",
    "Among Copilot users, what is the causal effect of increasing Copilot usage (e.g., from 5 to 10 actions per person-week) on burnout risk, i.e. after-hours collaboration hours?\n",
    "\n",
    "We frame this as a continuous-treatment (dose‚Äìresponse) problem: Copilot usage is the treatment \"dose,\" and we study both the marginal effect of an additional action and policy-relevant contrasts between usage levels (e.g., 5 ‚Üí 10 actions).\n",
    "\n",
    "‚Äî\n",
    "\n",
    "## Methods (summary)\n",
    "\n",
    "We use Double Machine Learning (DML) on person-level aggregated data:\n",
    "- Aggregate longitudinal data by person, taking means across all observed weeks for treatment, outcome, and time-varying controls.\n",
    "- Fit LinearDML with a spline featurizer on treatment to learn the marginal dose-response curve; compare to a baseline without featurization.\n",
    "- Estimate heterogeneity with CausalForestDML to identify which subgroups show different treatment effects.\n",
    "\n",
    "This cross-sectional approach compares individuals with different average Copilot usage levels, with DML providing robust adjustment for observed confounders. Deliverables include dose‚Äìresponse plots, marginal effects with CIs, and subgroup-level effect estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8927e6",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "We begin by importing the necessary libraries for our Double Machine Learning analysis:\n",
    "- **EconML**: Advanced causal inference estimators (LinearDML, CausalForestDML)\n",
    "- **Scikit-learn**: Feature transformers and ML models\n",
    "- **Data processing**: pandas, numpy for data manipulation\n",
    "- **Visualization**: matplotlib for plotting treatment effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af63530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "import vivainsights as vi\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# EconML imports for causal inference\n",
    "from econml.dml import LinearDML, CausalForestDML\n",
    "from econml.cate_interpreter import SingleTreeCateInterpreter\n",
    "\n",
    "# Scikit-learn imports for feature engineering and ML models\n",
    "from sklearn.preprocessing import PolynomialFeatures, SplineTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Generate subgroup combinations\n",
    "from itertools import combinations\n",
    "\n",
    "# Import custom modules\n",
    "script_dir = os.getcwd()\n",
    "sys.path.append(os.path.join(script_dir, 'modules'))\n",
    "\n",
    "from modules.data_processor import DataProcessor\n",
    "from modules.estimator import TreatmentEffectEstimator\n",
    "from modules.output_manager import OutputManager\n",
    "from modules.subgroup_analysis import (\n",
    "    create_subgroup_definition,\n",
    "    create_transition_matrix,\n",
    "    run_ate_for_subgroup,\n",
    "    identify_top_subgroups\n",
    ")\n",
    "from modules.sensitivity_analysis import (\n",
    "    calculate_evalue,\n",
    "    rosenbaum_bounds_approximation,\n",
    "    run_sensitivity_analysis\n",
    ")\n",
    "\n",
    "# ==================== ANALYSIS CONFIGURATION ====================\n",
    "# Toggle to control whether to find subgroups with NEGATIVE or POSITIVE effects\n",
    "# For after-hours collaboration, we're typically interested in NEGATIVE effects (reductions)\n",
    "FIND_NEGATIVE_EFFECTS = True  # Set to True for negative effects (bottom groups), False for positive effects (top groups)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ANALYSIS CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "if FIND_NEGATIVE_EFFECTS:\n",
    "    print(\"üîç Target: Subgroups with MOST NEGATIVE effects\")\n",
    "    print(\"   (i.e., largest reductions in after-hours collaboration)\")\n",
    "else:\n",
    "    print(\"üîç Target: Subgroups with MOST POSITIVE effects\") \n",
    "    print(\"   (i.e., largest increases in after-hours collaboration)\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "# ================================================================\n",
    "\n",
    "# Set up paths\n",
    "data_file_path = os.path.join(script_dir, '..', 'data', 'PersonQuery.Csv') # Update path\n",
    "\n",
    "# Set up output path\n",
    "output_base_dir = os.path.join(script_dir, '..', 'output', 'Subgroup Analysis - [YOUR COMPANY]') # Update path\n",
    "os.makedirs(output_base_dir, exist_ok=True)\n",
    "\n",
    "print(\"‚úì All imports successful!\")\n",
    "print(f\"Working directory: {script_dir}\")\n",
    "print(f\"Data file path: {data_file_path}\")\n",
    "print(f\"Data file exists: {os.path.exists(data_file_path)}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(123)\n",
    "plt.style.use('default')  # Clean plotting style\n",
    "\n",
    "# Read the data\n",
    "data = vi.import_query(data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b572916",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Columns in the dataset:\")\n",
    "print(data.columns.tolist())\n",
    "\n",
    "print(\"HR attributes in the dataset:\")\n",
    "hrvar_str = vi.extract_hr(data)\n",
    "print(hrvar_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d99f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Total'] = 'Total'\n",
    "\n",
    "# Analysis Configuration\n",
    "OUTCOME_VAR = 'After_hours_collaboration_hours'\n",
    "TREATMENT_VAR = 'Total_Copilot_actions_taken'\n",
    "PERSON_ID_VAR = 'PersonId'\n",
    "\n",
    "# Checking which Organization is high on the outcome variable\n",
    "ech_organization = vi.create_bar(\n",
    "    data = data,\n",
    "    metric = OUTCOME_VAR,\n",
    "    hrvar = 'Organization'\n",
    ")\n",
    "\n",
    "# Checking trend of after-hours collaboration over time\n",
    "ech_time = vi.create_line(\n",
    "    data = data,\n",
    "    metric = OUTCOME_VAR,\n",
    "    hrvar = 'Total'\n",
    ")\n",
    "\n",
    "# Checking trend of total copilot actions over time\n",
    "tch_time = vi.create_line(\n",
    "    data = data,\n",
    "    metric = TREATMENT_VAR,\n",
    "    hrvar = 'Total'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd57b6a",
   "metadata": {},
   "source": [
    "## 2. Data Filtering and Configuration\n",
    "\n",
    "<Placeholder for details here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10313eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define key variables for analysis\n",
    "# Note: There must be a minimum of two subgroup variables for analysis\n",
    "SUBGROUP_VARS = [\n",
    "    'FunctionType',\n",
    "    'IsManager',\n",
    "    'LevelDesignation',\n",
    "    'Organization'\n",
    "]\n",
    "\n",
    "NETWORK_VARS = [\n",
    "    'Internal_network_size',\n",
    "    'External_network_size',\n",
    "    'Strong_ties',\n",
    "    'Diverse_ties'\n",
    "]\n",
    "\n",
    "COLLABORATION_VARS = [\n",
    "    'Collaboration_hours',\n",
    "    'Available_to_focus_hours',\n",
    "    'Active_connected_hours',\n",
    "    'Uninterrupted_hours'\n",
    "]\n",
    "\n",
    "print(\"=== Data Filtering Phase ===\\n\")\n",
    "\n",
    "# Check original data structure\n",
    "print(f\"üìä Original Dataset:\")\n",
    "print(f\"   ‚Ä¢ Shape: {data.shape}\")\n",
    "print(f\"   ‚Ä¢ Unique individuals: {data[PERSON_ID_VAR].nunique()}\")\n",
    "\n",
    "# --- Simple start/end date filter ---\n",
    "# Set these as needed, e.g. '2025-06-01' and '2025-06-30'\n",
    "start_date_str = '2025-03-01'\n",
    "end_date_str   = '2025-06-30'\n",
    "\n",
    "data['MetricDate'] = pd.to_datetime(data['MetricDate'], errors='coerce')\n",
    "print(f\"   ‚Ä¢ Date range available: {data['MetricDate'].min()} to {data['MetricDate'].max()}\")\n",
    "if start_date_str and end_date_str:\n",
    "    start_date = pd.to_datetime(start_date_str)\n",
    "    end_date = pd.to_datetime(end_date_str)\n",
    "    mask = (data['MetricDate'] >= start_date) & (data['MetricDate'] <= end_date)\n",
    "    kept = int(mask.sum()); total = len(data)\n",
    "    print(f\"   ‚Ä¢ Applying date filter: {start_date.date()} to {end_date.date()} (kept {kept}/{total}, {kept/total:.1%})\")\n",
    "    data = data.loc[mask].copy()\n",
    "else:\n",
    "    print(\"   ‚Ä¢ No start/end date provided; skipping date filter\")\n",
    "\n",
    "# TOGGLE: Not applied because filter is not needed\n",
    "# Filter 1: Population filter\n",
    "# pop_mask = (data['JobFunction'] == 'Sales') & (data['ismanager'] == 'N') \n",
    "# print(f\"   ‚Ä¢ Records after filtering: {pop_mask.sum():,} ({pop_mask.mean():.1%})\")\n",
    "# data = data.loc[pop_mask].copy()\n",
    "# print(f\"   ‚úì Filtered to Sales ICs only\")\n",
    "\n",
    "# Filter 2: Copilot users only (Total_Copilot_actions_taken > 0)\n",
    "copilot_mask = data[TREATMENT_VAR] > 0\n",
    "print(f\"   ‚Ä¢ Copilot users (person-weeks): {copilot_mask.sum():,} ({copilot_mask.mean():.1%})\")\n",
    "data = data.loc[copilot_mask].copy()\n",
    "print(f\"   ‚úì Filtered to Copilot users only\")\n",
    "\n",
    "# Winsorize: cap treatment at 95th percentile for overlap\n",
    "treatment_95th = data[TREATMENT_VAR].quantile(0.95)\n",
    "print(f\"   ‚Ä¢ 95th percentile of {TREATMENT_VAR}: {treatment_95th}\")\n",
    "data.loc[data[TREATMENT_VAR] > treatment_95th, TREATMENT_VAR] = treatment_95th\n",
    "print(f\"   ‚úì Winsorized {TREATMENT_VAR} at the 95th percentile (upper cap)\")\n",
    "\n",
    "# Print final filtered dataset\n",
    "print(f\"\\nüìä Filtered Dataset:\")\n",
    "print(f\"   ‚Ä¢ Shape: {data.shape}\")\n",
    "print(f\"   ‚Ä¢ Unique individuals: {data[PERSON_ID_VAR].nunique()}\")\n",
    "\n",
    "# Print if in 'data' any variables are missing from SUBGROUP_VARS, NETWORK_VARS, or COLLABORATION_VARS\n",
    "missing_vars = []\n",
    "for var_list in [SUBGROUP_VARS, NETWORK_VARS, COLLABORATION_VARS]:\n",
    "    missing = set(var_list) - set(data.columns)\n",
    "    missing_vars.extend(missing)\n",
    "if missing_vars:\n",
    "    print(f\"   ‚Ä¢ Missing variables in 'data': {missing_vars}\")\n",
    "else:\n",
    "    print(f\"   ‚Ä¢ All required variables are present in 'data'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9968b75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a unique set of grouping variables by flattening the lists\n",
    "GROUPING_VARS = [PERSON_ID_VAR] + SUBGROUP_VARS\n",
    "GROUPING_VARS = list(set(GROUPING_VARS))  # Remove duplicates\n",
    "GROUPING_VARS = [var for var in GROUPING_VARS if var in data.columns]  # Only keep existing columns\n",
    "\n",
    "# Create a unique set of numeric variables to aggregate by mean\n",
    "AGG_VARS = NETWORK_VARS + COLLABORATION_VARS + [OUTCOME_VAR] + [TREATMENT_VAR]\n",
    "AGG_VARS = list(set(AGG_VARS))  # Remove duplicates\n",
    "AGG_VARS = [var for var in AGG_VARS if var in data.columns]  # Only keep existing columns\n",
    "\n",
    "# For 'data', group by GROUPING_VARS, aggregate by mean for AGG_VARS\n",
    "# Use lambda function with skipna=True to ignore missing values when calculating mean\n",
    "agg_dict = {var: lambda x: x.mean(skipna=True) for var in AGG_VARS}\n",
    "data_snapshot = data.groupby(GROUPING_VARS).agg(agg_dict).reset_index()\n",
    "\n",
    "# Flatten column names if they become multi-level due to lambda functions\n",
    "if isinstance(data_snapshot.columns, pd.MultiIndex):\n",
    "    data_snapshot.columns = ['_'.join(col).strip() if col[1] else col[0] for col in data_snapshot.columns]\n",
    "\n",
    "print(f\"‚úì Data snapshot created with shape: {data_snapshot.shape}\")\n",
    "print(f\"‚úì Grouping variables: {GROUPING_VARS}\")\n",
    "print(f\"‚úì Aggregated variables: {AGG_VARS}\")\n",
    "print(f\"‚úì Missing values ignored during mean calculation\")\n",
    "\n",
    "data_snapshot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35208a9",
   "metadata": {},
   "source": [
    "## 3. CATE Analysis to Identify Top Subgroups\n",
    "\n",
    "First, we'll use CausalForestDML to identify subgroups with heterogeneous treatment effects, then select the top 5 groups for detailed ATE analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2f9f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create necessary columns for cross-group analysis\n",
    "print(\"\\n=== Generating Subgroup Combinations ===\")\n",
    "\n",
    "# Create meaningful subgroup combinations\n",
    "subgroup_combinations = []\n",
    "min_group_size = 50  # Minimum observations per group for reliable analysis\n",
    "\n",
    "# Filter to variables that exist in the dataset and have reasonable number of categories\n",
    "available_group_vars = [var for var in SUBGROUP_VARS if var in data_snapshot.columns]\n",
    "print(f\"Available grouping variables: {available_group_vars}\")\n",
    "print(f\"Using cross-sectional data_snapshot with shape: {data_snapshot.shape}\")\n",
    "\n",
    "# Create all possible 2-way combinations using data_snapshot (cross-sectional data)\n",
    "for var1, var2 in combinations(available_group_vars, 2):\n",
    "    if var1 in data_snapshot.columns and var2 in data_snapshot.columns:\n",
    "        # Create combination groups using data_snapshot\n",
    "        group_combinations = data_snapshot.groupby([var1, var2]).size()\n",
    "        \n",
    "        # Filter groups with sufficient sample size\n",
    "        large_groups = group_combinations[group_combinations >= min_group_size]\n",
    "        \n",
    "        for (val1, val2), count in large_groups.items():\n",
    "            group_name = f\"{var1}_{val1}__and__{var2}_{val2}\".replace(' ', '_').replace('/', '_')\n",
    "            subgroup_combinations.append({\n",
    "                'name': group_name,\n",
    "                'var1': var1,\n",
    "                'val1': val1,\n",
    "                'var2': var2, \n",
    "                'val2': val2,\n",
    "                'size': count\n",
    "            })\n",
    "\n",
    "print(f\"Found {len(subgroup_combinations)} subgroup combinations with >= {min_group_size} observations\")\n",
    "\n",
    "# Show top combinations by size\n",
    "if subgroup_combinations:\n",
    "    sorted_combos = sorted(subgroup_combinations, key=lambda x: x['size'], reverse=True)\n",
    "    print(\"\\nTop 10 largest subgroups:\")\n",
    "    for combo in sorted_combos[:10]:\n",
    "        print(f\"  {combo['name']}: n={combo['size']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5871ff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for CATE analysis on subgroups\n",
    "print(\"\\n=== Preparing CATE Analysis ===\")\n",
    "\n",
    "# Prepare variables for heterogeneity analysis using data_snapshot\n",
    "X_vars = SUBGROUP_VARS + NETWORK_VARS[:2]  # Use key demographic and network variables\n",
    "available_X_vars = [var for var in X_vars if var in data_snapshot.columns and data_snapshot[var].dtype in ['object', 'category', 'int64', 'float64']]\n",
    "\n",
    "print(f\"Variables for heterogeneity analysis: {available_X_vars}\")\n",
    "\n",
    "# Create dummy variables for categorical features\n",
    "X_data = pd.get_dummies(data_snapshot[available_X_vars], drop_first=True)\n",
    "print(f\"Feature matrix shape after encoding: {X_data.shape}\")\n",
    "\n",
    "# Prepare treatment and outcome from data_snapshot\n",
    "T = data_snapshot[TREATMENT_VAR].values\n",
    "Y = data_snapshot[OUTCOME_VAR].values\n",
    "W = data_snapshot[COLLABORATION_VARS[:3]].fillna(0).values  # Control variables\n",
    "\n",
    "print(f\"Treatment variable range: {T.min():.2f} to {T.max():.2f}\")\n",
    "print(f\"Outcome variable range: {Y.min():.2f} to {Y.max():.2f}\")\n",
    "print(f\"Control variables shape: {W.shape}\")\n",
    "\n",
    "# Remove any rows with missing values\n",
    "valid_mask = ~(pd.isna(T) | pd.isna(Y) | np.isnan(X_data).any(axis=1) | np.isnan(W).any(axis=1))\n",
    "T_clean = T[valid_mask]\n",
    "Y_clean = Y[valid_mask] \n",
    "X_clean = X_data[valid_mask]\n",
    "W_clean = W[valid_mask]\n",
    "data_clean = data_snapshot[valid_mask].copy()\n",
    "\n",
    "print(f\"Clean data shape: {len(T_clean)} observations (cross-sectional)\")\n",
    "print(f\"Removed {len(T) - len(T_clean)} rows due to missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3ba27f",
   "metadata": {},
   "source": [
    "### CATE Effect Interpretation\n",
    "\n",
    "**Understanding `mean_effect` in Subgroup Analysis:**\n",
    "\n",
    "The `mean_effect` calculated for each subgroup represents the **average treatment effect for moving from 0 to the mean treatment level** within that subgroup, based on CausalForestDML estimates.\n",
    "\n",
    "**Key Details:**\n",
    "- **Treatment Comparison**: Effects are calculated using `T0=0` (baseline) vs `T1=T_clean.mean()` (dataset average)\n",
    "- **Units**: Hours of after-hours collaboration change by moving from 0 to average Copilot usage\n",
    "- **Interpretation**: \n",
    "  - If `mean_effect = -1.5` ‚Üí **1.5 hours REDUCTION** in after-hours collaboration per week\n",
    "  - If `mean_effect = +1.5` ‚Üí **1.5 hours INCREASE** in after-hours collaboration per week\n",
    "- **Direction**: Based on the `FIND_NEGATIVE_EFFECTS` toggle:\n",
    "  - `True` ‚Üí Find subgroups with most negative effects (largest reductions)\n",
    "  - `False` ‚Üí Find subgroups with most positive effects (largest increases)\n",
    "\n",
    "**Note**: This is a dose-response effect for policy-relevant treatment contrasts, not a per-unit marginal effect. The CausalForestDML captures heterogeneous, potentially non-linear effects across individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af137109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit CATE model to identify high-effect subgroups\n",
    "print(\"\\n=== Fitting CATE Model ===\")\n",
    "\n",
    "# Initialize CausalForestDML\n",
    "cate_estimator = CausalForestDML(\n",
    "    model_t=RandomForestRegressor(n_estimators=100, random_state=123),\n",
    "    model_y=RandomForestRegressor(n_estimators=100, random_state=123), \n",
    "    cv=3,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "# Fit the CATE model\n",
    "print(\"Fitting CausalForestDML...\")\n",
    "cate_estimator.fit(Y_clean, T_clean, X=X_clean, W=W_clean)\n",
    "print(\"‚úì CATE model fitted successfully\")\n",
    "\n",
    "# Estimate treatment effects for each individual\n",
    "print(\"Estimating individual treatment effects...\")\n",
    "treatment_effects = cate_estimator.effect(X_clean, T0=0, T1=T_clean.mean())\n",
    "\n",
    "print(f\"Individual treatment effects range: {treatment_effects.min():.3f} to {treatment_effects.max():.3f}\")\n",
    "print(f\"Mean treatment effect: {treatment_effects.mean():.3f}\")\n",
    "\n",
    "# Add treatment effects back to clean data\n",
    "data_clean['individual_treatment_effect'] = treatment_effects\n",
    "print(\"‚úì Individual treatment effects calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a5588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify top 5 subgroups with highest/lowest treatment effects based on configuration\n",
    "if FIND_NEGATIVE_EFFECTS:\n",
    "    print(\"\\n=== Identifying Subgroups with MOST NEGATIVE Effects ===\")\n",
    "    print(\"(Largest reductions in after-hours collaboration)\")\n",
    "else:\n",
    "    print(\"\\n=== Identifying Subgroups with MOST POSITIVE Effects ===\")\n",
    "    print(\"(Largest increases in after-hours collaboration)\")\n",
    "\n",
    "subgroup_effects = []\n",
    "\n",
    "for combo in subgroup_combinations:\n",
    "    # Create mask for this subgroup\n",
    "    mask = ((data_clean[combo['var1']] == combo['val1']) & \n",
    "            (data_clean[combo['var2']] == combo['val2']))\n",
    "    \n",
    "    if mask.sum() < min_group_size:  # Skip if too small after cleaning\n",
    "        continue\n",
    "        \n",
    "    subgroup_data = data_clean[mask]\n",
    "    mean_effect = subgroup_data['individual_treatment_effect'].mean()\n",
    "    std_effect = subgroup_data['individual_treatment_effect'].std()\n",
    "    n_obs = len(subgroup_data)\n",
    "    n_users = subgroup_data[PERSON_ID_VAR].nunique()\n",
    "    \n",
    "    # Calculate statistical significance (t-test against 0)\n",
    "    from scipy import stats\n",
    "    if n_obs > 1 and std_effect > 0:\n",
    "        t_stat = mean_effect / (std_effect / np.sqrt(n_obs))\n",
    "        p_value = 2 * (1 - stats.t.cdf(abs(t_stat), n_obs - 1))\n",
    "    else:\n",
    "        p_value = 1.0\n",
    "    \n",
    "    subgroup_effects.append({\n",
    "        'name': combo['name'],\n",
    "        'var1': combo['var1'],\n",
    "        'val1': combo['val1'], \n",
    "        'var2': combo['var2'],\n",
    "        'val2': combo['val2'],\n",
    "        'mean_effect': mean_effect,\n",
    "        'std_effect': std_effect,\n",
    "        'p_value': p_value,\n",
    "        'n_observations': n_obs,\n",
    "        'n_users': n_users,\n",
    "        'significant': p_value < 0.05\n",
    "    })\n",
    "\n",
    "# Sort by mean effect based on configuration toggle\n",
    "subgroup_effects_df = pd.DataFrame(subgroup_effects)\n",
    "significant_subgroups = subgroup_effects_df[subgroup_effects_df['significant']].sort_values(\n",
    "    'mean_effect', \n",
    "    ascending=FIND_NEGATIVE_EFFECTS  # ascending=True gets most negative (bottom), ascending=False gets most positive (top)\n",
    ")\n",
    "\n",
    "print(f\"Found {len(significant_subgroups)} statistically significant subgroups (p < 0.05)\")\n",
    "if FIND_NEGATIVE_EFFECTS:\n",
    "    print(f\"Bottom 10 subgroups by treatment effect (most negative):\")\n",
    "else:\n",
    "    print(f\"Top 10 subgroups by treatment effect (most positive):\")\n",
    "print(significant_subgroups[['name', 'mean_effect', 'p_value', 'n_observations', 'n_users']].head(10))\n",
    "\n",
    "# Select top/bottom 5 for detailed ATE analysis\n",
    "top_5_subgroups = significant_subgroups.head(5)\n",
    "if FIND_NEGATIVE_EFFECTS:\n",
    "    print(f\"\\nüìä Selected 5 subgroups with MOST NEGATIVE effects for ATE analysis:\")\n",
    "else:\n",
    "    print(f\"\\nüìä Selected 5 subgroups with MOST POSITIVE effects for ATE analysis:\")\n",
    "\n",
    "for idx, (_, subgroup_info) in enumerate(top_5_subgroups.iterrows(), 1):\n",
    "    effect_direction = \"‚Üì\" if subgroup_info['mean_effect'] < 0 else \"‚Üë\"\n",
    "    print(f\"  {idx}. {subgroup_info['name']}\")\n",
    "    print(f\"     Effect: {effect_direction} {subgroup_info['mean_effect']:.4f} hours (p={subgroup_info['p_value']:.4f})\")\n",
    "\n",
    "# Save summary\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "significant_subgroups_path = os.path.join(output_base_dir, f\"significant_subgroups_{timestamp}.csv\")\n",
    "significant_subgroups.to_csv(significant_subgroups_path, index=False)\n",
    "print(f\"\\n‚úì Full significant subgroups list saved to: {significant_subgroups_path}\")\n",
    "\n",
    "significant_subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3a0737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== Visualization of Selected Subgroups ====================\n",
    "\n",
    "# Bar chart visualizing significant sub-groups and their mean treatment effect\n",
    "# Based on significant_subgroups\n",
    "\n",
    "# Prepare data for visualization - use ALL significant subgroups\n",
    "plot_data = significant_subgroups.copy()\n",
    "plot_data['short_name'] = plot_data.apply(\n",
    "    lambda row: f\"{row['val1']}\\n{row['val2']}\", \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Determine figure size based on number of subgroups\n",
    "n_subgroups = len(plot_data)\n",
    "fig_width = max(16, n_subgroups * 0.5)  # At least 16 inches, scale with number of groups\n",
    "fig_height = 8\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "\n",
    "# Create bar chart\n",
    "x_pos = np.arange(len(plot_data))\n",
    "bars = ax.bar(x_pos, plot_data['mean_effect'], \n",
    "               color=['#0078D4' if effect > 0 else '#107C10' for effect in plot_data['mean_effect']],\n",
    "               alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (idx, row) in enumerate(plot_data.iterrows()):\n",
    "    height = row['mean_effect']\n",
    "    ax.text(i, height + 0.002, f\"{height:.4f}\", \n",
    "            ha='center', va='bottom', fontsize=8, fontweight='bold', rotation=0)\n",
    "    # Add p-value below bar (only if p < 0.01 to avoid clutter)\n",
    "    if row['p_value'] < 0.01:\n",
    "        ax.text(i, min(plot_data['mean_effect']) * 0.95, f\"p<.01\", \n",
    "                ha='center', va='top', fontsize=6, style='italic', color='gray')\n",
    "\n",
    "# Customize plot\n",
    "ax.set_xlabel('Subgroup', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Mean Treatment Effect (hours)', fontsize=12, fontweight='bold')\n",
    "effect_type = \"Most Negative\" if FIND_NEGATIVE_EFFECTS else \"Most Positive\"\n",
    "ax.set_title(f'Treatment Effects for All {n_subgroups} Significant Subgroups\\n(Impact of Copilot on After-Hours Collaboration)', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "# Set x-axis labels\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(plot_data['short_name'], rotation=90, ha='center', fontsize=7)\n",
    "\n",
    "# Add horizontal line at zero\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=0.8, alpha=0.5)\n",
    "\n",
    "# Add grid\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Add legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='#0078D4', alpha=0.7, edgecolor='black', label='Positive Effect (Increase)'),\n",
    "    Patch(facecolor='#107C10', alpha=0.7, edgecolor='black', label='Negative Effect (Decrease)')\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='upper right', fontsize=10)\n",
    "\n",
    "# Add summary statistics text box\n",
    "n_positive = (plot_data['mean_effect'] > 0).sum()\n",
    "n_negative = (plot_data['mean_effect'] < 0).sum()\n",
    "avg_effect = plot_data['mean_effect'].mean()\n",
    "textstr = f'Total: {n_subgroups}\\nPositive: {n_positive}\\nNegative: {n_negative}\\nAvg Effect: {avg_effect:.4f}h'\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "ax.text(0.02, 0.98, textstr, transform=ax.transAxes, fontsize=10,\n",
    "        verticalalignment='top', bbox=props)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the plot\n",
    "plot_filename = f\"all_significant_subgroups_effects_{timestamp}.png\"\n",
    "plot_path = os.path.join(output_base_dir, plot_filename)\n",
    "fig.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"\\n‚úì Plot saved to: {plot_path}\")\n",
    "print(f\"‚úì Visualized {n_subgroups} significant subgroups\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a24c0b",
   "metadata": {},
   "source": [
    "### Important Note on EconML X vs W Parameters\n",
    "\n",
    "**Critical distinction for LinearDML vs CausalForestDML:**\n",
    "\n",
    "- **LinearDML**: \n",
    "  - `X` = Effect modifiers (variables that create heterogeneous treatment effects)\n",
    "  - `W` = Confounders (variables for backdoor adjustment/controlling bias)\n",
    "  \n",
    "- **CausalForestDML**: \n",
    "  - `X` = Used for both heterogeneity AND confounding control\n",
    "  - `W` = Additional controls (optional)\n",
    "\n",
    "**Our approach:**\n",
    "- `X` (effect modifiers): Network variables (expect different effects by network size)\n",
    "- `W` (confounders): Demographics + collaboration controls (need to adjust for these)\n",
    "- **Featurized model**: `œÑ(X) = f(network_vars)` controlling for demographics\n",
    "- **Baseline model**: `œÑ = constant` controlling for demographics\n",
    "\n",
    "**Model Comparison:**\n",
    "- **ATE (Featurized)**: Uses `treatment_featurizer` (SplineTransformer) to capture non-linear dose-response relationships. Can model diminishing returns, thresholds, and varying effects across treatment levels.\n",
    "- **ATE (Baseline)**: Uses `treatment_featurizer=None` for linear effects only. Assumes constant effect per unit treatment increase across all dose levels. Serves as benchmark to test if non-linear modeling adds value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a399d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ATE analysis for each top subgroup and generate outputs\n",
    "print(\"\\n=== Running ATE Analysis for Top Subgroups ===\")\n",
    "\n",
    "successful_analyses = []\n",
    "\n",
    "for idx, (_, subgroup_info) in enumerate(top_5_subgroups.iterrows(), 1):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"SUBGROUP {idx}/5: {subgroup_info['name']}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Create subgroup mask and extract data\n",
    "    mask = ((data_clean[subgroup_info['var1']] == subgroup_info['val1']) & \n",
    "            (data_clean[subgroup_info['var2']] == subgroup_info['val2']))\n",
    "    subgroup_data = data_clean[mask].copy()\n",
    "    \n",
    "    # Run ATE analysis\n",
    "    ate_analysis = run_ate_for_subgroup(subgroup_data, subgroup_info, treatment_var=TREATMENT_VAR, outcome_var=OUTCOME_VAR)\n",
    "    \n",
    "    if ate_analysis is None:\n",
    "        continue\n",
    "    \n",
    "    # Create subgroup-specific output directory\n",
    "    subgroup_dir = os.path.join(output_base_dir, f\"Subgroup_{idx}_{subgroup_info['name']}\")\n",
    "    os.makedirs(subgroup_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. Save ATE results\n",
    "    ate_results_path = os.path.join(subgroup_dir, f\"ate_results_{TREATMENT_VAR}_{timestamp}.csv\")\n",
    "    ate_analysis['ate_results'].to_csv(ate_results_path, index=False)\n",
    "    print(f\"‚úì ATE results saved: {ate_results_path}\")\n",
    "    \n",
    "    # 2. Save subgroup definition\n",
    "    definition_path = os.path.join(subgroup_dir, \"subgroup_definition.txt\")\n",
    "    definition = create_subgroup_definition(\n",
    "        subgroup_info['var1'], subgroup_info['val1'], \n",
    "        subgroup_info['var2'], subgroup_info['val2']\n",
    "    )\n",
    "    with open(definition_path, 'w') as f:\n",
    "        f.write(definition)\n",
    "    print(f\"‚úì Subgroup definition saved: {definition_path}\")\n",
    "    \n",
    "    # 3. Create and save transition matrix\n",
    "    transition_matrix = create_transition_matrix(ate_analysis['subgroup_clean'], TREATMENT_VAR, PERSON_ID_VAR)\n",
    "    if not transition_matrix.empty:\n",
    "        transition_path = os.path.join(subgroup_dir, f\"transition_matrix_{TREATMENT_VAR}_{timestamp}.csv\")\n",
    "        transition_matrix.to_csv(transition_path, index=False)\n",
    "        print(f\"‚úì Transition matrix saved: {transition_path}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Transition matrix empty - insufficient data for buckets\")\n",
    "    \n",
    "    # 4. Create and save ATE plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "    \n",
    "    treatment_grid = ate_analysis['ate_results']['Treatment']\n",
    "    ate_featurized = ate_analysis['ate_results']['ATE_Featurized']\n",
    "    ate_baseline = ate_analysis['ate_results']['ATE_Baseline']\n",
    "    ci_lower_feat = ate_analysis['ate_results']['CI_Lower_Featurized']\n",
    "    ci_upper_feat = ate_analysis['ate_results']['CI_Upper_Featurized']\n",
    "    ci_lower_base = ate_analysis['ate_results']['CI_Lower_Baseline']\n",
    "    ci_upper_base = ate_analysis['ate_results']['CI_Upper_Baseline']\n",
    "    \n",
    "    # Plot featurized ATE with confidence interval\n",
    "    ax.plot(treatment_grid, ate_featurized, 'b-', linewidth=2, label='ATE (Featurized)')\n",
    "    ax.fill_between(treatment_grid, ci_lower_feat, ci_upper_feat, alpha=0.3, color='blue')\n",
    "    \n",
    "    # Plot baseline ATE with confidence interval\n",
    "    ax.plot(treatment_grid, ate_baseline, 'r--', linewidth=2, label='ATE (Baseline)')\n",
    "    ax.fill_between(treatment_grid, ci_lower_base, ci_upper_base, alpha=0.3, color='red')\n",
    "    \n",
    "    # Add horizontal line at 0\n",
    "    ax.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    \n",
    "    ax.set_xlabel(f'{TREATMENT_VAR}')\n",
    "    ax.set_ylabel(f'Average Treatment Effect on {OUTCOME_VAR}')\n",
    "    ax.set_title(f'ATE Analysis: {subgroup_info[\"name\"]}\\n(n={len(ate_analysis[\"subgroup_clean\"])} obs, {ate_analysis[\"subgroup_clean\"][PERSON_ID_VAR].nunique()} users)')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plot_path = os.path.join(subgroup_dir, f\"ate_plot_{TREATMENT_VAR}_{timestamp}.png\")\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"‚úì ATE plot saved: {plot_path}\")\n",
    "    \n",
    "    # Store successful analysis info\n",
    "    successful_analyses.append({\n",
    "        'subgroup': subgroup_info['name'],\n",
    "        'directory': subgroup_dir,\n",
    "        'mean_effect': subgroup_info['mean_effect'],\n",
    "        'p_value': subgroup_info['p_value'],\n",
    "        'n_observations': len(ate_analysis['subgroup_clean']),\n",
    "        'n_users': ate_analysis['subgroup_clean'][PERSON_ID_VAR].nunique()\n",
    "    })\n",
    "    \n",
    "    print(f\"‚úÖ Completed analysis for subgroup: {subgroup_info['name']}\")\n",
    "\n",
    "print(f\"\\nüéâ ANALYSIS COMPLETE!\")\n",
    "print(f\"Successfully analyzed {len(successful_analyses)} subgroups\")\n",
    "print(f\"Results saved to: {output_base_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a2adae",
   "metadata": {},
   "source": [
    "## 4. Summary and Results\n",
    "\n",
    "Let's review the results of our subgroup analysis and show the key findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b201acdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary of results\n",
    "print(\"=\"*60)\n",
    "print(\"SUBGROUP ANALYSIS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if successful_analyses:\n",
    "    summary_df = pd.DataFrame(successful_analyses)\n",
    "    \n",
    "    print(f\"\\nüìä Successfully analyzed {len(successful_analyses)} subgroups with positive treatment effects:\")\n",
    "    print(\"\\nSubgroup Details:\")\n",
    "    for i, analysis in enumerate(successful_analyses, 1):\n",
    "        print(f\"\\n{i}. {analysis['subgroup']}\")\n",
    "        print(f\"   ‚Ä¢ Mean treatment effect: {analysis['mean_effect']:.4f}\")\n",
    "        print(f\"   ‚Ä¢ Statistical significance: p = {analysis['p_value']:.4f}\")\n",
    "        print(f\"   ‚Ä¢ Sample size: {analysis['n_observations']} observations ({analysis['n_users']} users)\")\n",
    "        print(f\"   ‚Ä¢ Output directory: {analysis['directory']}\")\n",
    "    \n",
    "    print(f\"\\nüìÅ All results saved to: {output_base_dir}\")\n",
    "    \n",
    "    print(f\"\\nüìã Generated files for each subgroup:\")\n",
    "    print(f\"   ‚Ä¢ ate_results_{TREATMENT_VAR}_[timestamp].csv - ATE estimates with confidence intervals\")\n",
    "    print(f\"   ‚Ä¢ subgroup_definition.txt - Logical definition of the subgroup\")\n",
    "    print(f\"   ‚Ä¢ transition_matrix_{TREATMENT_VAR}_[timestamp].csv - Treatment level transitions\") \n",
    "    print(f\"   ‚Ä¢ ate_plot_{TREATMENT_VAR}_[timestamp].png - Visualization of treatment effects\")\n",
    "    \n",
    "    print(f\"\\nüéØ KEY FINDINGS:\")\n",
    "    print(f\"   ‚Ä¢ Treatment variable: {TREATMENT_VAR}\")\n",
    "    print(f\"   ‚Ä¢ Outcome variable: {OUTCOME_VAR}\")\n",
    "    print(f\"   ‚Ä¢ Analysis method: CATE (CausalForestDML) ‚Üí ATE (LinearDML)\")\n",
    "    print(f\"   ‚Ä¢ Significance threshold: p < 0.05\")\n",
    "    print(f\"   ‚Ä¢ Total subgroups tested: {len(subgroup_combinations)}\")\n",
    "    print(f\"   ‚Ä¢ Significant positive effects: {len(successful_analyses)}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No subgroups with significant positive treatment effects were found.\")\n",
    "    print(\"Consider:\")\n",
    "    print(\"   ‚Ä¢ Relaxing the significance threshold\")\n",
    "    print(\"   ‚Ä¢ Using different subgroup definitions\") \n",
    "    print(\"   ‚Ä¢ Checking data quality and sample sizes\")\n",
    "\n",
    "print(f\"\\n‚úÖ Analysis completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8105ae70",
   "metadata": {},
   "source": [
    "## 5. Sensitivity Analysis for Unobserved Confounding\n",
    "\n",
    "To assess the robustness of our causal conclusions, we conduct sensitivity analysis to determine how strong unobserved confounding would need to be to explain away our findings. We implement two complementary approaches:\n",
    "\n",
    "### Methods Overview:\n",
    "- **Rosenbaum Bounds**: Tests sensitivity to hidden bias by examining how strong an unmeasured confounder would need to be to overturn significant results\n",
    "- **E-values**: Quantifies the minimum strength of association an unmeasured confounder would need to have with both treatment and outcome to explain away the observed effect\n",
    "\n",
    "Both methods help us understand the degree of unobserved confounding that would be required to nullify our treatment effect estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bc2724",
   "metadata": {},
   "source": [
    "### 5.1 Overall CATE Model Sensitivity Analysis\n",
    "\n",
    "First, we assess the sensitivity of our overall CATE findings from the CausalForestDML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b17844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity analysis for overall CATE model\n",
    "print(\"=== CATE Model Sensitivity Analysis ===\\n\")\n",
    "\n",
    "# Check if we have the required column\n",
    "if 'individual_treatment_effect' not in data_clean.columns:\n",
    "    print(\"‚ö†Ô∏è WARNING: 'individual_treatment_effect' column not found in data_clean\")\n",
    "    print(\"Please ensure you have run the CATE analysis cells (Cell 22) before running sensitivity analysis.\")\n",
    "    print(\"\\nThe CATE analysis must be executed first to generate individual treatment effects.\")\n",
    "    print(\"This cell cannot proceed without those effects.\\n\")\n",
    "    \n",
    "    # Create placeholder variables to prevent downstream errors\n",
    "    sensitivity_results_overall = {\n",
    "        'error': 'individual_treatment_effect column not found - run CATE analysis first'\n",
    "    }\n",
    "    overall_evalue = {'evalue_point': None, 'evalue_ci': None}\n",
    "    overall_rosenbaum = {'critical_gamma': None, 'original_p_value': None}\n",
    "else:\n",
    "    # Get overall treatment effects from CATE model\n",
    "    overall_effects = data_clean['individual_treatment_effect'].values\n",
    "    mean_overall_effect = np.mean(overall_effects)\n",
    "    std_overall_effect = np.std(overall_effects)\n",
    "\n",
    "    print(f\"Overall CATE Results:\")\n",
    "    print(f\"  ‚Ä¢ Mean treatment effect: {mean_overall_effect:.4f} hours\")\n",
    "    print(f\"  ‚Ä¢ Standard deviation: {std_overall_effect:.4f} hours\")\n",
    "    print(f\"  ‚Ä¢ Sample size: {len(overall_effects)} individuals\")\n",
    "\n",
    "    # Calculate E-value for overall effect\n",
    "    # Use approximate confidence interval based on standard error\n",
    "    se_overall = std_overall_effect / np.sqrt(len(overall_effects))\n",
    "    ci_lower_overall = mean_overall_effect - 1.96 * se_overall\n",
    "    ci_upper_overall = mean_overall_effect + 1.96 * se_overall\n",
    "\n",
    "    overall_evalue = calculate_evalue(\n",
    "        estimate=mean_overall_effect,\n",
    "        confidence_interval_lower=ci_lower_overall,\n",
    "        confidence_interval_upper=ci_upper_overall\n",
    "    )\n",
    "\n",
    "    print(f\"\\nüìä E-value Analysis (Overall CATE):\")\n",
    "    print(f\"  ‚Ä¢ Point estimate E-value: {overall_evalue['evalue_point']:.2f}\")\n",
    "    print(f\"  ‚Ä¢ Confidence interval E-value: {overall_evalue['evalue_ci']:.2f}\")\n",
    "    print(f\"\\nInterpretation:\")\n",
    "    print(f\"  An unmeasured confounder would need to be associated with both\")\n",
    "    print(f\"  Copilot usage and after-hours collaboration by a risk ratio of\")\n",
    "    print(f\"  {overall_evalue['evalue_point']:.1f} to fully explain away the observed effect.\")\n",
    "\n",
    "    # Rosenbaum bounds analysis for overall effects\n",
    "    overall_rosenbaum = rosenbaum_bounds_approximation(overall_effects)\n",
    "\n",
    "    print(f\"\\nüìä Rosenbaum Bounds Analysis (Overall CATE):\")\n",
    "    print(f\"  ‚Ä¢ Original p-value: {overall_rosenbaum['original_p_value']:.2e}\")\n",
    "    if overall_rosenbaum['critical_gamma']:\n",
    "        print(f\"  ‚Ä¢ Critical Gamma (Œì): {overall_rosenbaum['critical_gamma']:.1f}\")\n",
    "    else:\n",
    "        print(f\"  ‚Ä¢ Critical Gamma (Œì): >5.0 (beyond tested range)\")\n",
    "    print(overall_rosenbaum['interpretation'])\n",
    "\n",
    "    # Save sensitivity results\n",
    "    sensitivity_results_overall = {\n",
    "        'analysis_type': 'Overall_CATE',\n",
    "        'sample_size': len(overall_effects),\n",
    "        'mean_effect': mean_overall_effect,\n",
    "        'standard_error': se_overall,\n",
    "        'evalue_point': overall_evalue['evalue_point'],\n",
    "        'evalue_ci': overall_evalue['evalue_ci'],\n",
    "        'rosenbaum_critical_gamma': overall_rosenbaum['critical_gamma'],\n",
    "        'original_p_value': overall_rosenbaum['original_p_value']\n",
    "    }\n",
    "\n",
    "print(f\"\\n‚úì Overall CATE sensitivity analysis completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d74edb",
   "metadata": {},
   "source": [
    "### 5.2 Top Subgroups Sensitivity Analysis\n",
    "\n",
    "Now we examine the sensitivity of our top-performing subgroups to unobserved confounding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4767e863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity analysis for top subgroups\n",
    "print(\"=== Top Subgroups Sensitivity Analysis ===\\n\")\n",
    "\n",
    "# Check if we have the required data\n",
    "if 'individual_treatment_effect' not in data_clean.columns:\n",
    "    print(\"‚ö†Ô∏è WARNING: 'individual_treatment_effect' column not found in data_clean\")\n",
    "    print(\"Skipping subgroup sensitivity analysis.\\n\")\n",
    "    subgroup_sensitivity_results = []\n",
    "elif 'top_5_subgroups' not in dir():\n",
    "    print(\"‚ö†Ô∏è WARNING: 'top_5_subgroups' not defined\")\n",
    "    print(\"Please run the CATE subgroup identification cells first.\\n\")\n",
    "    subgroup_sensitivity_results = []\n",
    "else:\n",
    "    subgroup_sensitivity_results = []\n",
    "\n",
    "    for idx, (_, subgroup_info) in enumerate(top_5_subgroups.iterrows(), 1):\n",
    "        print(f\"--- Subgroup {idx}: {subgroup_info['name']} ---\")\n",
    "        \n",
    "        # Get subgroup data and individual treatment effects\n",
    "        mask = ((data_clean[subgroup_info['var1']] == subgroup_info['val1']) & \n",
    "                (data_clean[subgroup_info['var2']] == subgroup_info['val2']))\n",
    "        subgroup_data = data_clean[mask]\n",
    "        \n",
    "        if len(subgroup_data) < 10:  # Skip if too small\n",
    "            print(f\"‚ö†Ô∏è Skipping - insufficient sample size ({len(subgroup_data)})\")\n",
    "            continue\n",
    "        \n",
    "        subgroup_effects = subgroup_data['individual_treatment_effect'].values\n",
    "        mean_effect = subgroup_info['mean_effect']\n",
    "        std_effect = subgroup_info['std_effect']\n",
    "        se_effect = std_effect / np.sqrt(len(subgroup_effects))\n",
    "        \n",
    "        print(f\"  ‚Ä¢ Mean effect: {mean_effect:.4f} hours\")\n",
    "        print(f\"  ‚Ä¢ Standard error: {se_effect:.4f} hours\") \n",
    "        print(f\"  ‚Ä¢ P-value: {subgroup_info['p_value']:.4f}\")\n",
    "        print(f\"  ‚Ä¢ Sample size: {len(subgroup_effects)} individuals\")\n",
    "        \n",
    "        # Calculate E-value\n",
    "        ci_lower_sub = mean_effect - 1.96 * se_effect\n",
    "        ci_upper_sub = mean_effect + 1.96 * se_effect\n",
    "        \n",
    "        subgroup_evalue = calculate_evalue(\n",
    "            estimate=mean_effect,\n",
    "            confidence_interval_lower=ci_lower_sub,\n",
    "            confidence_interval_upper=ci_upper_sub\n",
    "        )\n",
    "        \n",
    "        print(f\"  ‚Ä¢ E-value (point): {subgroup_evalue['evalue_point']:.2f}\")\n",
    "        print(f\"  ‚Ä¢ E-value (CI): {subgroup_evalue['evalue_ci']:.2f}\")\n",
    "        \n",
    "        # Rosenbaum bounds\n",
    "        subgroup_rosenbaum = rosenbaum_bounds_approximation(subgroup_effects)\n",
    "        critical_gamma = subgroup_rosenbaum['critical_gamma']\n",
    "        \n",
    "        if critical_gamma:\n",
    "            print(f\"  ‚Ä¢ Rosenbaum Œì: {critical_gamma:.1f}\")\n",
    "        else:\n",
    "            print(f\"  ‚Ä¢ Rosenbaum Œì: >3.0\")\n",
    "        \n",
    "        # Store results\n",
    "        subgroup_sensitivity_results.append({\n",
    "            'subgroup_name': subgroup_info['name'],\n",
    "            'rank': idx,\n",
    "            'mean_effect': mean_effect,\n",
    "            'p_value': subgroup_info['p_value'],\n",
    "            'sample_size': len(subgroup_effects),\n",
    "            'evalue_point': subgroup_evalue['evalue_point'],\n",
    "            'evalue_ci': subgroup_evalue['evalue_ci'],\n",
    "            'rosenbaum_gamma': critical_gamma,\n",
    "            'robustness_score': min(subgroup_evalue['evalue_ci'], critical_gamma if critical_gamma else 3.0)\n",
    "        })\n",
    "        \n",
    "        print()\n",
    "\n",
    "# Create summary dataframe\n",
    "if len(subgroup_sensitivity_results) > 0:\n",
    "    sensitivity_df = pd.DataFrame(subgroup_sensitivity_results)\n",
    "    sensitivity_df = sensitivity_df.sort_values('robustness_score', ascending=False)\n",
    "\n",
    "    print(\"üìä SENSITIVITY SUMMARY (Top 5 Subgroups)\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"{'Rank':<4} {'Subgroup':<35} {'E-val':<6} {'Œì':<6} {'Robust':<6}\")\n",
    "    print(\"-\"*60)\n",
    "\n",
    "    for _, row in sensitivity_df.iterrows():\n",
    "        gamma_str = f\"{row['rosenbaum_gamma']:.1f}\" if row['rosenbaum_gamma'] else \">3.0\"\n",
    "        print(f\"{row['rank']:<4} {row['subgroup_name'][:34]:<35} {row['evalue_ci']:<6.1f} {gamma_str:<6} {row['robustness_score']:<6.1f}\")\n",
    "\n",
    "    print(f\"\\nMost robust subgroup: {sensitivity_df.iloc[0]['subgroup_name']}\")\n",
    "    print(f\"Robustness score: {sensitivity_df.iloc[0]['robustness_score']:.1f}\")\n",
    "\n",
    "    print(f\"\\n‚úì Subgroup sensitivity analysis completed\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No subgroup sensitivity results to display\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593d12ac",
   "metadata": {},
   "source": [
    "### 5.3 Robustness Summary and Interpretation\n",
    "\n",
    "Let's create visualizations and provide comprehensive interpretation of our sensitivity analysis results.\n",
    "\n",
    "---\n",
    "\n",
    "## üìñ How to Interpret Sensitivity Analysis Metrics\n",
    "\n",
    "### **E-value: Robustness to Unmeasured Confounding**\n",
    "\n",
    "The **E-value** quantifies how strong an unmeasured confounder would need to be to completely explain away the observed effect.\n",
    "\n",
    "**What it measures:** The minimum strength of association (risk ratio) that an unmeasured confounder would need to have with BOTH the treatment (Copilot usage) AND the outcome (after-hours collaboration) to fully explain away the observed effect.\n",
    "\n",
    "**Interpretation Guidelines:**\n",
    "- **E-value < 1.5**: ‚ö†Ô∏è **Potentially fragile** - Relatively weak confounding could explain away the effect\n",
    "- **E-value 1.5-2.0**: üî∂ **Moderate robustness** - Would require moderate confounding\n",
    "- **E-value > 2.0**: ‚úÖ **Strong robustness** - Would require substantial confounding  \n",
    "- **E-value > 3.0**: ‚úÖ‚úÖ **Very robust** - Highly unlikely unmeasured confounders are this strong\n",
    "\n",
    "**Example:** An E-value of 1.30 means an unmeasured confounder would need to increase the likelihood of both Copilot usage AND after-hours collaboration by at least 30% each to completely nullify the observed effect.\n",
    "\n",
    "**Plausible Confounders to Consider:**\n",
    "- Job role complexity (high-complexity roles ‚Üí more tool adoption + more collaboration)\n",
    "- Team culture and norms\n",
    "- Individual motivation/proactivity\n",
    "- Manager support and expectations\n",
    "\n",
    "---\n",
    "\n",
    "### **Rosenbaum's Œì (Gamma): Hidden Bias in Treatment Assignment**\n",
    "\n",
    "**Rosenbaum bounds** test how much hidden bias can exist in treatment assignment before the result becomes statistically non-significant.\n",
    "\n",
    "**What it measures:** The maximum odds ratio of treatment assignment due to unobserved factors while maintaining statistical significance.\n",
    "\n",
    "**Interpretation Guidelines:**\n",
    "- **Œì < 1.5**: ‚ö†Ô∏è **Fragile** - Small amounts of hidden bias could eliminate significance\n",
    "- **Œì = 1.5-2.0**: üî∂ **Moderate robustness** - Tolerates moderate hidden bias\n",
    "- **Œì > 2.0**: ‚úÖ **Strong robustness** - Results remain significant with substantial hidden bias\n",
    "- **Œì > 3.0**: ‚úÖ‚úÖ **Very robust** - Highly resistant to hidden bias\n",
    "\n",
    "**Example:** A Œì of 2.0 means that even if two similar individuals differed by a factor of 2 in their odds of receiving treatment (due to unobserved factors), the finding would still be statistically significant.\n",
    "\n",
    "**Key Distinction:** Rosenbaum Œì tests whether statistical **significance** survives hidden bias, while E-value tests whether the effect **magnitude** could be explained by confounding. Both matter!\n",
    "\n",
    "---\n",
    "\n",
    "### **How to Report Findings:**\n",
    "\n",
    "**Strong Results (E-value > 2.0, Œì > 2.0):**\n",
    "> \"The findings are robust to unmeasured confounding. An unmeasured confounder would need to be associated with both treatment and outcome by a risk ratio of [E-value] to fully explain the effect, and the statistical significance is maintained even under substantial hidden bias (Œì = [value]).\"\n",
    "\n",
    "**Moderate Results (E-value 1.5-2.0, Œì > 2.0):**\n",
    "> \"While the statistical significance is robust to hidden bias (Œì > [value]), the effect magnitude could be explained by a moderately strong unmeasured confounder (E-value = [value]). Plausible confounders such as [examples] should be considered.\"\n",
    "\n",
    "**Fragile Results (E-value < 1.5):**\n",
    "> \"The findings are potentially sensitive to unmeasured confounding. A confounder with relatively modest associations (E-value = [value]) with both treatment and outcome could explain the observed effect. Caution is warranted in causal interpretation.\"\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d2c455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization and comprehensive summary\n",
    "print(\"=== COMPREHENSIVE SENSITIVITY ANALYSIS SUMMARY ===\\n\")\n",
    "\n",
    "# Check if we have sensitivity results to visualize\n",
    "if len(subgroup_sensitivity_results) == 0:\n",
    "    print(\"‚ö†Ô∏è No subgroup sensitivity results available for visualization\")\n",
    "    print(\"Please ensure the previous sensitivity analysis cells completed successfully.\\n\")\n",
    "else:\n",
    "    # Create visualization of sensitivity results\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "    # Plot 1: E-values vs Treatment Effects\n",
    "    effects = [r['mean_effect'] for r in subgroup_sensitivity_results]\n",
    "    evalues = [r['evalue_ci'] for r in subgroup_sensitivity_results]\n",
    "    names = [r['subgroup_name'][:20] + '...' if len(r['subgroup_name']) > 20 else r['subgroup_name'] \n",
    "             for r in subgroup_sensitivity_results]\n",
    "    \n",
    "    ax1.scatter(effects, evalues, s=100, alpha=0.7, c='steelblue')\n",
    "    for i, name in enumerate(names):\n",
    "        ax1.annotate(f'{i+1}', (effects[i], evalues[i]), \n",
    "                    xytext=(5, 5), textcoords='offset points', fontsize=10)\n",
    "    \n",
    "    ax1.set_xlabel('Mean Treatment Effect (Hours)')\n",
    "    ax1.set_ylabel('E-value (Confidence Interval)')\n",
    "    ax1.set_title('Treatment Effect vs E-value\\n(Higher E-value = More Robust)')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.axhline(y=2.0, color='red', linestyle='--', alpha=0.5, label='E-value = 2.0')\n",
    "    ax1.legend()\n",
    "\n",
    "    # Plot 2: Rosenbaum Gamma values\n",
    "    gammas = [r['rosenbaum_gamma'] if r['rosenbaum_gamma'] else 3.0 \n",
    "              for r in subgroup_sensitivity_results]\n",
    "    ranks = [r['rank'] for r in subgroup_sensitivity_results]\n",
    "    \n",
    "    colors = ['green' if g >= 2.0 else 'orange' if g >= 1.5 else 'red' for g in gammas]\n",
    "    \n",
    "    bars = ax2.bar(ranks, gammas, color=colors, alpha=0.7)\n",
    "    ax2.set_xlabel('Subgroup Rank')\n",
    "    ax2.set_ylabel('Critical Gamma (Œì)')\n",
    "    ax2.set_title('Rosenbaum Bounds by Subgroup\\n(Higher Œì = More Robust)')\n",
    "    ax2.set_xticks(ranks)\n",
    "    ax2.axhline(y=2.0, color='red', linestyle='--', alpha=0.5, label='Œì = 2.0 threshold')\n",
    "    ax2.axhline(y=1.5, color='orange', linestyle='--', alpha=0.5, label='Œì = 1.5 threshold')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    sensitivity_plot_path = os.path.join(output_base_dir, f\"sensitivity_analysis_{timestamp}.png\")\n",
    "    plt.savefig(sensitivity_plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"‚úì Sensitivity plot saved: {sensitivity_plot_path}\")\n",
    "\n",
    "# Comprehensive interpretation\n",
    "print(f\"\\nüéØ ROBUSTNESS INTERPRETATION:\")\n",
    "print(f\"=\"*50)\n",
    "\n",
    "# Check if overall results exist\n",
    "if 'overall_evalue' in dir() and overall_evalue.get('evalue_ci') is not None:\n",
    "    print(f\"\\nüìà Overall CATE Model:\")\n",
    "    evalue_ci_str = f\"{overall_evalue['evalue_ci']:.1f}\" if overall_evalue['evalue_ci'] else \"N/A\"\n",
    "    print(f\"  ‚Ä¢ E-value: {evalue_ci_str}\")\n",
    "    \n",
    "    if 'overall_rosenbaum' in dir() and overall_rosenbaum.get('critical_gamma'):\n",
    "        print(f\"  ‚Ä¢ Rosenbaum Œì: {overall_rosenbaum['critical_gamma']:.1f}\")\n",
    "    else:\n",
    "        print(f\"  ‚Ä¢ Rosenbaum Œì: >3.0\")\n",
    "else:\n",
    "    print(f\"\\nüìà Overall CATE Model:\")\n",
    "    print(f\"  ‚Ä¢ Results not available (run Cell 28 first)\")\n",
    "\n",
    "# Process subgroup robustness if we have results\n",
    "if len(subgroup_sensitivity_results) > 0:\n",
    "    robustness_levels = {\n",
    "        'Very Robust': [],\n",
    "        'Moderately Robust': [],\n",
    "        'Potentially Fragile': []\n",
    "    }\n",
    "\n",
    "    for result in subgroup_sensitivity_results:\n",
    "        score = result['robustness_score']\n",
    "        name = result['subgroup_name'][:30]\n",
    "        \n",
    "        if score >= 2.0:\n",
    "            robustness_levels['Very Robust'].append((name, score))\n",
    "        elif score >= 1.5:\n",
    "            robustness_levels['Moderately Robust'].append((name, score))\n",
    "        else:\n",
    "            robustness_levels['Potentially Fragile'].append((name, score))\n",
    "\n",
    "    print(f\"\\nüìä Subgroup Robustness Categories:\")\n",
    "    for category, subgroups in robustness_levels.items():\n",
    "        print(f\"\\n{category} (n={len(subgroups)}):\")\n",
    "        for name, score in subgroups:\n",
    "            print(f\"  ‚Ä¢ {name}: {score:.1f}\")\n",
    "\n",
    "    print(f\"\\nüí° KEY INSIGHTS:\")\n",
    "    print(f\"  ‚Ä¢ Results requiring Œì > 2.0 or E-value > 2.0 are considered robust\")\n",
    "    print(f\"  ‚Ä¢ An unmeasured confounder would need substantial associations\")\n",
    "    print(f\"    with both treatment and outcome to explain away these effects\")\n",
    "    print(f\"  ‚Ä¢ Higher-ranked subgroups generally show stronger robustness\")\n",
    "\n",
    "    # Save comprehensive sensitivity results\n",
    "    sensitivity_summary = {\n",
    "        'overall_analysis': sensitivity_results_overall if 'sensitivity_results_overall' in dir() else {},\n",
    "        'subgroup_analysis': subgroup_sensitivity_results,\n",
    "        'robustness_categories': robustness_levels,\n",
    "        'timestamp': timestamp,\n",
    "        'interpretation': {\n",
    "            'very_robust_count': len(robustness_levels['Very Robust']),\n",
    "            'moderate_robust_count': len(robustness_levels['Moderately Robust']),\n",
    "            'fragile_count': len(robustness_levels['Potentially Fragile']),\n",
    "            'most_robust_subgroup': sensitivity_df.iloc[0]['subgroup_name'] if 'sensitivity_df' in dir() and len(sensitivity_df) > 0 else None\n",
    "        }\n",
    "    }\n",
    "\n",
    "    sensitivity_results_path = os.path.join(output_base_dir, f\"sensitivity_analysis_results_{timestamp}.json\")\n",
    "    with open(sensitivity_results_path, 'w') as f:\n",
    "        # Convert numpy types to native Python types for JSON serialization\n",
    "        def convert_numpy(obj):\n",
    "            if isinstance(obj, np.integer):\n",
    "                return int(obj)\n",
    "            elif isinstance(obj, np.floating):\n",
    "                return float(obj)\n",
    "            elif isinstance(obj, np.ndarray):\n",
    "                return obj.tolist()\n",
    "            return obj\n",
    "        \n",
    "        import json\n",
    "        json.dump(sensitivity_summary, f, indent=2, default=convert_numpy)\n",
    "\n",
    "    print(f\"\\n‚úÖ SENSITIVITY ANALYSIS COMPLETE!\")\n",
    "    print(f\"üìÅ Results saved to: {sensitivity_results_path}\")\n",
    "    if 'sensitivity_plot_path' in dir():\n",
    "        print(f\"üìä Visualization saved to: {sensitivity_plot_path}\")\n",
    "\n",
    "    print(f\"\\nüèÅ CONCLUSION:\")\n",
    "    print(f\"The sensitivity analysis suggests that our findings are\")\n",
    "    print(f\"{'robust' if len(robustness_levels['Very Robust']) >= 2 else 'moderately robust' if len(robustness_levels['Moderately Robust']) >= 2 else 'potentially sensitive'}\")\n",
    "    print(f\"to unobserved confounding, with {len(robustness_levels['Very Robust'])} subgroups\")\n",
    "    print(f\"showing very high robustness to hidden bias.\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è No subgroup sensitivity results available for interpretation\")\n",
    "    print(f\"Please run the previous sensitivity analysis cells first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
